<head>
	<title>MoDem</title>
	<meta property="og:title" content="MoDem">
	<meta property="og:description" content="Accelerating Visual Model-Based Reinforcement Learning with Demonstrations">
	<link rel="stylesheet" href="style.css">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
	</script>
	<script type="text/javascript" async
  		src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
	</script>
	<script type="text/javascript">
		function toggle(id) {
			var e = document.getElementById(id);
			if(e.style.display == 'block')
				e.style.display = 'none';
			else
				e.style.display = 'block';
		}
	</script>
</head>
<div class="header" id="top">
	<h1><span style="font-weight: bolder; color: #c03d3e;">MoDem:</span> Accelerating Visual Model-Based Reinforcement Learning with Demonstrations</h1>
	<table class="authors">
		<tbody>
			<tr>
				<td>
					<h4>
						Anonymous Authors<br/>
						<br/>
						<span class="authors-affiliation" style="font-size: 0.85em;"><a href="https://openreview.net/forum?id=JdTnc9gjVfJ">ICLR 2023 Submission</a></span>
					</h4>
				</td>
			</tr>
		</tbody>
	</table>
</div>
<div class="content">
	<div class="figure" style="height: 384px; background-image: url(images/teaser.png);"></div>
	<div style="margin: auto; margin-top: -24px;">
		<p>
			<span class="bold">Success rate (%) in sparse reward tasks.</span> Given only 5 human demonstrations and a limited amount of online interaction, our method solves <span class="bold">21</span> hard robotics tasks from pixels, including dexterous manipulation, pick-and-place, and locomotion, while baselines fail to solve most tasks with limited data.
		</p>
	</div>
	<div class="hr"></div>
	<div>
		<h2>Abstract</h2>
		<p class="abstract">
			Poor sample efficiency continues to be the primary challenge for deployment of deep Reinforcement Learning (RL) algorithms for real-world applications, and in particular for visuo-motor control. Model-based RL has the potential to be highly sample efficient by concurrently learning a world model and using synthetic rollouts for planning and policy improvement. However, in practice, sample-efficient learning with model-based RL is bottlenecked by the exploration challenge. In this work, we find that leveraging just a handful of demonstrations can dramatically improve the sample-efficiency of model-based RL. Simply appending demonstrations to the interaction dataset, however, does not suffice. We identify key ingredients for leveraging demonstrations in model learning -- policy pretraining, targeted exploration, and oversampling of demonstration data -- which forms the three phases of our model-based RL framework. We empirically study three complex visuo-motor control domains and find that our method is <span class="bold">260%</span>-<span class="bold">350%</span> more successful in completing sparse reward tasks compared to prior approaches in the low data regime (<span class="bold">100K</span> interaction steps, <span class="bold">5</span> demonstrations).
		</p>
	</div>
	<div class="hr"></div>
	<div>
		<h2>Results</h2>
		<div class="figure" style="height: 256px; background-image: url(images/main-result.png);"></div>
		<div class="figure-caption" style="margin-top: -16px;">
			<p>
				Our model-based method, <span class="bold" style="color:#c03d3e">MoDem</span>, solves challenging visuo-motor control tasks with <span class="highlight">sparse rewards</span> and <span class="highlight">high-dimensional action spaces</span> in 100K interaction steps given only 5 demonstrations, outperforming prior state-of-the-art methods by a large margin in this setting.
			</p>
		</div>
		<div class="figure-caption">
			<p>
				Below, we visualize trajectories generated by our method for a subset of the 18 sparse reward tasks that we consider.
			</p>
		</div>
		<div class="content-video" style="margin-bottom: 48px">
			<div class="content-video-container">
				<video playsinline="" autoplay="" loop="" preload="" muted="" width="24.5%">
					<source src="samples/5.mp4" type="video/mp4"/>
				</video>
				<video playsinline="" autoplay="" loop="" preload="" muted="" width="24.5%">
					<source src="samples/4.mp4" type="video/mp4"/>
				</video>
				<video playsinline="" autoplay="" loop="" preload="" muted="" width="24.5%">
					<source src="samples/10.mp4" type="video/mp4"/>
				</video>
				<video playsinline="" autoplay="" loop="" preload="" muted="" width="24.5%">
					<source src="samples/2.mp4" type="video/mp4"/>
				</video>
				<video playsinline="" autoplay="" loop="" preload="" muted="" width="24.5%">
					<source src="samples/8.mp4" type="video/mp4"/>
				</video>
				<video playsinline="" autoplay="" loop="" preload="" muted="" width="24.5%">
					<source src="samples/9.mp4" type="video/mp4"/>
				</video>
				<video playsinline="" autoplay="" loop="" preload="" muted="" width="24.5%">
					<source src="samples/7.mp4" type="video/mp4"/>
				</video>
				<video playsinline="" autoplay="" loop="" preload="" muted="" width="24.5%">
					<source src="samples/1.mp4" type="video/mp4"/>
				</video>
			</div>
		</div>
	</div>
</div>
<footer>
<a href="#top" class="bold">To top &UpArrow;</a>
</footer>
